{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_trn = pd.read_csv('train.csv', index_col=0)\n",
    "data_tst = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25766, 256)\n",
      "(11042, 255)\n"
     ]
    }
   ],
   "source": [
    "print (data_trn.shape)\n",
    "print (data_tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "Name: Trans24, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Read Datasets\n",
    "\n",
    "recodecustomer={'Old':1,'New':0}\n",
    "recodenew={'Enable':1,'Not-Enable':0}\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "#print(pd.isnull(train).any())\n",
    "\n",
    "#fillna(value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "train['Cust_status']=train['Cust_status'].map(recodecustomer)\n",
    "train['Trans24']=train['Trans24'].map(recodenew)\n",
    "train['Trans25']=train['Trans25'].map(recodenew)\n",
    "train['Trans26']=train['Trans26'].map(recodenew)\n",
    "train['Trans27']=train['Trans27'].map(recodenew)\n",
    "print(train['Trans24'].head(2))\n",
    "\n",
    "y_train=train[\"Active_Customer\"]\n",
    "train=train.where(pd.notnull(train), train.mean(), axis='columns')\n",
    "#train=train.fillna(0)\n",
    "test=test.where(pd.notnull(test), test.mean(), axis='columns')\n",
    "\n",
    "#train=train.fillna(0)\n",
    "#test=test.fillna(0)\n",
    "train=train.drop([\"Cust_id\"],axis=1)\n",
    "colsToDrop = [\"Promotion5\",\"Promotion6\",\"Promotion7\",\"Promotion8\",\"Promotion9\",\"Promotion10\",\n",
    "                      \"Promotion11\",\"Promotion18\",\"Promotion25\",\"Promotion32\",\"Promotion39\",\"Promotion46\"\n",
    "                     ,\"Promotion12\",\"Promotion19\",\"Promotion26\",\"Promotion33\",\"Promotion40\",\"Promotion47\",\n",
    "                     \"Promotion13\",\"Promotion20\",\"Promotion27\",\"Promotion34\",\"Promotion41\",\"Promotion48\",\n",
    "                     \"Promotion14\",\"Promotion21\",\"Promotion28\",\"Promotion35\",\"Promotion42\",\n",
    "                     \"Promotion15\",\"Promotion22\",\"Promotion29\",\"Promotion36\",\"Promotion43\",\n",
    "                     \"Promotion16\",\"Promotion23\",\"Promotion30\",\"Promotion37\",\"Promotion44\",\n",
    "                     \"Promotion17\",\"Promotion24\",\"Promotion31\",\"Promotion38\",\"Promotion45\"]\n",
    "promotions_train = pd.DataFrame(train, columns=colsToDrop)\n",
    "promotions_test = pd.DataFrame(test, columns=colsToDrop)\n",
    "\n",
    "train=train.drop([\"Promotion5\",\"Promotion6\",\"Promotion7\",\"Promotion8\",\"Promotion9\",\"Promotion10\",\n",
    "                     \"Promotion11\",\"Promotion18\",\"Promotion25\",\"Promotion32\",\"Promotion39\",\"Promotion46\"\n",
    "                     ,\"Promotion12\",\"Promotion19\",\"Promotion26\",\"Promotion33\",\"Promotion40\",\"Promotion47\",\n",
    "                     \"Promotion13\",\"Promotion20\",\"Promotion27\",\"Promotion34\",\"Promotion41\",\"Promotion48\",\n",
    "                     \"Promotion14\",\"Promotion21\",\"Promotion28\",\"Promotion35\",\"Promotion42\",\n",
    "                     \"Promotion15\",\"Promotion22\",\"Promotion29\",\"Promotion36\",\"Promotion43\",\n",
    "                     \"Promotion16\",\"Promotion23\",\"Promotion30\",\"Promotion37\",\"Promotion44\",\n",
    "                     \"Promotion17\",\"Promotion24\",\"Promotion31\",\"Promotion38\",\"Promotion45\"],axis=1)\n",
    "test=test.drop([\"Promotion5\",\"Promotion6\",\"Promotion7\",\"Promotion8\",\"Promotion9\",\"Promotion10\",\n",
    "                     \"Promotion11\",\"Promotion18\",\"Promotion25\",\"Promotion32\",\"Promotion39\",\"Promotion46\"\n",
    "                     ,\"Promotion12\",\"Promotion19\",\"Promotion26\",\"Promotion33\",\"Promotion40\",\"Promotion47\",\n",
    "                     \"Promotion13\",\"Promotion20\",\"Promotion27\",\"Promotion34\",\"Promotion41\",\"Promotion48\",\n",
    "                     \"Promotion14\",\"Promotion21\",\"Promotion28\",\"Promotion35\",\"Promotion42\",\n",
    "                     \"Promotion15\",\"Promotion22\",\"Promotion29\",\"Promotion36\",\"Promotion43\",\n",
    "                     \"Promotion16\",\"Promotion23\",\"Promotion30\",\"Promotion37\",\"Promotion44\",\n",
    "                     \"Promotion17\",\"Promotion24\",\"Promotion31\",\"Promotion38\",\"Promotion45\"],axis=1)\n",
    "train=train.drop([\"Active_Customer\"],axis=1)\n",
    "\n",
    "\n",
    "test['Cust_status']=test['Cust_status'].map(recodecustomer)\n",
    "test['Trans24']=test['Trans24'].map(recodenew)\n",
    "test['Trans25']=test['Trans25'].map(recodenew)\n",
    "test['Trans26']=test['Trans26'].map(recodenew)\n",
    "test['Trans27']=test['Trans27'].map(recodenew)\n",
    "\n",
    "y_id = test[\"Cust_id\"]\n",
    "#test = test.drop([\"Cust_id\"],axis=1)\n",
    "#test=test.drop([\"Promotion5\"],axis=1)\n",
    "#test=test.drop([\"Promotion6\"],axis=1)\n",
    "#test=test.drop([\"Promotion7\"],axis=1)\n",
    "#test=test.drop([\"Promotion8\"],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing PCA on Promotions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "#Assumed you have training and test data set as train and test\n",
    "# Create PCA obeject \n",
    "pca= decomposition.PCA(n_components=1) #default value of k =min(n_sample, n_features)\n",
    "# For Factor analysis\n",
    "#fa= decomposition.FactorAnalysis()\n",
    "# Reduced the dimension of training dataset using PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "promotions_train_new=normalize(promotions_train, norm='l2', axis=1, copy=True)\n",
    "\n",
    "promotions_train_reduced = pca.fit_transform(promotions_train_new)\n",
    "train['reduced_columns']=promotions_train_reduced\n",
    "promotions_test_new=normalize(promotions_test, norm='l2', axis=1, copy=True)\n",
    "\n",
    "promotions_test_reduced = pca.fit_transform(promotions_test_new)\n",
    "test['reduced_columns']=promotions_test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17263, 212)\n",
      "(8503, 212)\n",
      "(17263,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(train, y_train, test_size=0.33, random_state=42)\n",
    "#for original train test data\n",
    "#train_matrix = train.as_matrix()\n",
    "#test_matrix=test.as_matrix()\n",
    "\n",
    "y_train_matrix = Y_train.as_matrix()\n",
    "\n",
    "#for test train split\n",
    "train_matrix= X_train.as_matrix()\n",
    "test_matrix = X_test.as_matrix()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pd.DataFrame.to_csv(train,'data2.csv')\n",
    "#print(train.head())\n",
    "print train_matrix.shape\n",
    "print test_matrix.shape\n",
    "print y_train_matrix.shape\n",
    "#print promotions.shape\n",
    "#print(pd.isnull(train).any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(class_weight = \"balanced\")\n",
    "logistic.fit(train_matrix,y_train_matrix)\n",
    "y_test = logistic.predict(test_matrix)\n",
    "train_test = logistic.predict(train_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66270727978360577"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preds = pd.DataFrame({\"Cust_id\":y_id,\"Active_Customer\":y_test})\n",
    "#preds = preds.set_index('Cust_id')\n",
    "#preds.to_csv('first.csv')\n",
    "\n",
    "\n",
    "accuracy_score(Y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm1 = xgb.XGBClassifier(max_depth=5, n_estimators=600, learning_rate=0.025).fit(train_matrix, y_train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('testin accuracy', 0.67611431259555455)\n",
      "('training accuracy', 0.77425708161964901)\n"
     ]
    }
   ],
   "source": [
    "predictions = gbm1.predict(test_matrix)\n",
    "train_predictions = gbm1.predict(train_matrix)\n",
    "print(\"testin accuracy\",accuracy_score(Y_test,predictions))\n",
    "print(\"training accuracy\",accuracy_score(Y_train,train_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({\"Cust_id\":y_id,\"Active_Customer\":predictions})\n",
    "preds = preds.set_index('Cust_id')\n",
    "preds.to_csv('third.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create Random Forest object\n",
    "model_RF= RandomForestClassifier(criterion=\"entropy\")\n",
    "# Train the model using the training sets and check score\n",
    "model_RF.fit(train_matrix,y_train_matrix)\n",
    "#Predict Output\n",
    "predicted_randomforest= model_RF.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "#Assumed you have training and test data set as train and test\n",
    "# Create PCA obeject \n",
    "pca= decomposition.PCA(n_components=20) #default value of k =min(n_sample, n_features)\n",
    "# For Factor analysis\n",
    "#fa= decomposition.FactorAnalysis()\n",
    "# Reduced the dimension of training dataset using PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "train_matrix_nor=normalize(train_matrix, norm='l2', axis=1, copy=True)\n",
    "test_matrix_nor=normalize(test_matrix, norm='l2', axis=1, copy=True)\n",
    "train_reduced = pca.fit_transform(train_matrix_nor)\n",
    "#Reduced the dimension of test dataset\n",
    "test_reduced = pca.transform(test_matrix_nor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn import svm\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC() \n",
    "# there is various option associated with it, this is simple for classification. You can refer link, for mo# re detail.\n",
    "# Train the model using the training sets and check score\n",
    "model.fit(train_reduced,y_train_matrix)\n",
    "#model.score(X, y)\n",
    "#Predict Output\n",
    "predicted= model.predict(test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64647771374808893"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XGBoost after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66329530753851584"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(train_reduced, y_train_matrix)\n",
    "predictions = gbm.predict(test_reduced)\n",
    "accuracy_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65224038574620724"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic1 = LogisticRegression(class_weight = \"balanced\")\n",
    "logistic1.fit(train_reduced,y_train_matrix)\n",
    "y_test = logistic1.predict(test_reduced)\n",
    "\n",
    "accuracy_score(Y_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create Random Forest object\n",
    "model1= RandomForestClassifier(criterion=\"entropy\")\n",
    "# Train the model using the training sets and check score\n",
    "model1.fit(train_reduced,y_train_matrix)\n",
    "#Predict Output\n",
    "predicted_randomforest= model1.predict(test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63271786428319421"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,predicted_randomforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "eclf1 = VotingClassifier(estimators=[('GB', gbm1), ('LR', logistic),('SVM',model)], voting='hard')\n",
    "eclf1 = eclf1.fit(train_matrix,y_train_matrix)\n",
    "predicted_ensemble=eclf1.predict(test_matrix)\n",
    "predicted_train_ensemble=eclf1.predict(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.659179113254\n",
      "0.665295719168\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(Y_test,predicted_ensemble)\n",
    "print accuracy_score(Y_train,predicted_train_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
